{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "#14-Regression with TensorFlow.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "copyright",
        "5fsbamUAVuCP",
        "0o3jHPj9llA8",
        "s9hGTw7O6Mtu"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alfianAH/ml-resource/blob/main/14_Regression_with_TensorFlow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "copyright"
      },
      "source": [
        "#### Copyright 2020 Google LLC."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "both",
        "id": "hMqWDc_m6rUC"
      },
      "source": [
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c2hPzRb6j_CA"
      },
      "source": [
        "# Regression with TensorFlow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9x88D_U-4oTH"
      },
      "source": [
        "We have trained a linear regression model in TensorFlow and used it to predict housing prices. However, the model didn't perform as well as we would have liked it to. In this lab, we will build a neural network to try to tackle the same regression problem and see if we can get better results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6AaBjI9hmqnT"
      },
      "source": [
        "## Loading and Preparing the Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4f3CKqFUqL2-"
      },
      "source": [
        "The dataset we'll use for this Colab contains California housing information taken from the 1990 census data. We explored this data in a previous lab, so we won't do an analysis here. As a reminder, the documentation for the dataset can be found [on Kaggle](https://www.kaggle.com/camnugent/california-housing-prices)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MxiIKhP4E2Zr"
      },
      "source": [
        "Upload your `kaggle.json` file and run the code block below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tkRBt4c813MP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8ada50c-1bf7-4513-81f3-54c1bf916cd4"
      },
      "source": [
        "! chmod 600 kaggle.json && (ls ~/.kaggle 2>/dev/null || mkdir ~/.kaggle) && mv kaggle.json ~/.kaggle/ && echo 'Done'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "chmod: cannot access 'kaggle.json': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WdltN0vY18H_"
      },
      "source": [
        "Once you are done, use the `kaggle` command to download the file into the lab."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wt4pCnny2Am2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b535e8ed-9b37-492b-9964-ea3a97719565"
      },
      "source": [
        "!kaggle datasets download camnugent/california-housing-prices\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "california-housing-prices.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "california-housing-prices.zip  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5aJqOuak2FCs"
      },
      "source": [
        "We now have a file called `california-housing-prices.zip` that we can load into a `DataFrame`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ivCDWnwE2Zx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "outputId": "5c6ac849-f55e-47ee-b13e-6ff787879981"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "housing_df = pd.read_csv('california-housing-prices.zip')\n",
        "\n",
        "housing_df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>longitude</th>\n",
              "      <th>latitude</th>\n",
              "      <th>housing_median_age</th>\n",
              "      <th>total_rooms</th>\n",
              "      <th>total_bedrooms</th>\n",
              "      <th>population</th>\n",
              "      <th>households</th>\n",
              "      <th>median_income</th>\n",
              "      <th>median_house_value</th>\n",
              "      <th>ocean_proximity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-122.23</td>\n",
              "      <td>37.88</td>\n",
              "      <td>41.0</td>\n",
              "      <td>880.0</td>\n",
              "      <td>129.0</td>\n",
              "      <td>322.0</td>\n",
              "      <td>126.0</td>\n",
              "      <td>8.3252</td>\n",
              "      <td>452600.0</td>\n",
              "      <td>NEAR BAY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-122.22</td>\n",
              "      <td>37.86</td>\n",
              "      <td>21.0</td>\n",
              "      <td>7099.0</td>\n",
              "      <td>1106.0</td>\n",
              "      <td>2401.0</td>\n",
              "      <td>1138.0</td>\n",
              "      <td>8.3014</td>\n",
              "      <td>358500.0</td>\n",
              "      <td>NEAR BAY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-122.24</td>\n",
              "      <td>37.85</td>\n",
              "      <td>52.0</td>\n",
              "      <td>1467.0</td>\n",
              "      <td>190.0</td>\n",
              "      <td>496.0</td>\n",
              "      <td>177.0</td>\n",
              "      <td>7.2574</td>\n",
              "      <td>352100.0</td>\n",
              "      <td>NEAR BAY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-122.25</td>\n",
              "      <td>37.85</td>\n",
              "      <td>52.0</td>\n",
              "      <td>1274.0</td>\n",
              "      <td>235.0</td>\n",
              "      <td>558.0</td>\n",
              "      <td>219.0</td>\n",
              "      <td>5.6431</td>\n",
              "      <td>341300.0</td>\n",
              "      <td>NEAR BAY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-122.25</td>\n",
              "      <td>37.85</td>\n",
              "      <td>52.0</td>\n",
              "      <td>1627.0</td>\n",
              "      <td>280.0</td>\n",
              "      <td>565.0</td>\n",
              "      <td>259.0</td>\n",
              "      <td>3.8462</td>\n",
              "      <td>342200.0</td>\n",
              "      <td>NEAR BAY</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20635</th>\n",
              "      <td>-121.09</td>\n",
              "      <td>39.48</td>\n",
              "      <td>25.0</td>\n",
              "      <td>1665.0</td>\n",
              "      <td>374.0</td>\n",
              "      <td>845.0</td>\n",
              "      <td>330.0</td>\n",
              "      <td>1.5603</td>\n",
              "      <td>78100.0</td>\n",
              "      <td>INLAND</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20636</th>\n",
              "      <td>-121.21</td>\n",
              "      <td>39.49</td>\n",
              "      <td>18.0</td>\n",
              "      <td>697.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>356.0</td>\n",
              "      <td>114.0</td>\n",
              "      <td>2.5568</td>\n",
              "      <td>77100.0</td>\n",
              "      <td>INLAND</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20637</th>\n",
              "      <td>-121.22</td>\n",
              "      <td>39.43</td>\n",
              "      <td>17.0</td>\n",
              "      <td>2254.0</td>\n",
              "      <td>485.0</td>\n",
              "      <td>1007.0</td>\n",
              "      <td>433.0</td>\n",
              "      <td>1.7000</td>\n",
              "      <td>92300.0</td>\n",
              "      <td>INLAND</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20638</th>\n",
              "      <td>-121.32</td>\n",
              "      <td>39.43</td>\n",
              "      <td>18.0</td>\n",
              "      <td>1860.0</td>\n",
              "      <td>409.0</td>\n",
              "      <td>741.0</td>\n",
              "      <td>349.0</td>\n",
              "      <td>1.8672</td>\n",
              "      <td>84700.0</td>\n",
              "      <td>INLAND</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20639</th>\n",
              "      <td>-121.24</td>\n",
              "      <td>39.37</td>\n",
              "      <td>16.0</td>\n",
              "      <td>2785.0</td>\n",
              "      <td>616.0</td>\n",
              "      <td>1387.0</td>\n",
              "      <td>530.0</td>\n",
              "      <td>2.3886</td>\n",
              "      <td>89400.0</td>\n",
              "      <td>INLAND</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>20640 rows × 10 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       longitude  latitude  ...  median_house_value  ocean_proximity\n",
              "0        -122.23     37.88  ...            452600.0         NEAR BAY\n",
              "1        -122.22     37.86  ...            358500.0         NEAR BAY\n",
              "2        -122.24     37.85  ...            352100.0         NEAR BAY\n",
              "3        -122.25     37.85  ...            341300.0         NEAR BAY\n",
              "4        -122.25     37.85  ...            342200.0         NEAR BAY\n",
              "...          ...       ...  ...                 ...              ...\n",
              "20635    -121.09     39.48  ...             78100.0           INLAND\n",
              "20636    -121.21     39.49  ...             77100.0           INLAND\n",
              "20637    -121.22     39.43  ...             92300.0           INLAND\n",
              "20638    -121.32     39.43  ...             84700.0           INLAND\n",
              "20639    -121.24     39.37  ...             89400.0           INLAND\n",
              "\n",
              "[20640 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KI9ElSbPje6j"
      },
      "source": [
        "Next we can define which columns are features and which is the target.\n",
        "\n",
        "We'll also make a separate list of our numeric columns."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wTjb8Gn-92v2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c474474-6417-4b3f-8a97-c3938170ac96"
      },
      "source": [
        "target_column = 'median_house_value'\n",
        "feature_columns = [c for c in housing_df.columns if c != target_column]\n",
        "numeric_feature_columns = [c for c in feature_columns if c != 'ocean_proximity']\n",
        "\n",
        "target_column, feature_columns, numeric_feature_columns"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('median_house_value',\n",
              " ['longitude',\n",
              "  'latitude',\n",
              "  'housing_median_age',\n",
              "  'total_rooms',\n",
              "  'total_bedrooms',\n",
              "  'population',\n",
              "  'households',\n",
              "  'median_income',\n",
              "  'ocean_proximity'],\n",
              " ['longitude',\n",
              "  'latitude',\n",
              "  'housing_median_age',\n",
              "  'total_rooms',\n",
              "  'total_bedrooms',\n",
              "  'population',\n",
              "  'households',\n",
              "  'median_income'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wrOyGuN_k74i"
      },
      "source": [
        "We also reduced the value of our targets by a factor in the previous lab. This reduction in magnitude was done to help the model train faster. Let's do that again."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1RkwE7QGlAjG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0fa6c85-774b-4d24-e32f-6107207ebc66"
      },
      "source": [
        "TARGET_FACTOR = 100000\n",
        "\n",
        "housing_df[target_column] /= TARGET_FACTOR\n",
        "\n",
        "housing_df[target_column].describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    20640.000000\n",
              "mean         2.068558\n",
              "std          1.153956\n",
              "min          0.149990\n",
              "25%          1.196000\n",
              "50%          1.797000\n",
              "75%          2.647250\n",
              "max          5.000010\n",
              "Name: median_house_value, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EzTdkcVS2ZCk"
      },
      "source": [
        "And we filled in some missing `total_bedrooms` values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LByQBpsy2b--",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "outputId": "e420f15c-8fba-4608-c79d-6e5ef524ef14"
      },
      "source": [
        "has_all_data = housing_df[~housing_df['total_bedrooms'].isna()]\n",
        "\n",
        "sums = has_all_data[['total_bedrooms', 'total_rooms']].sum().tolist()\n",
        "\n",
        "bedrooms_to_total_rooms_ratio = sums[0] / sums[1]\n",
        "\n",
        "missing_total_bedrooms_idx = housing_df['total_bedrooms'].isna()\n",
        "\n",
        "housing_df.loc[missing_total_bedrooms_idx, 'total_bedrooms'] = housing_df[\n",
        "    missing_total_bedrooms_idx]['total_rooms'] * bedrooms_to_total_rooms_ratio\n",
        "\n",
        "housing_df.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>longitude</th>\n",
              "      <th>latitude</th>\n",
              "      <th>housing_median_age</th>\n",
              "      <th>total_rooms</th>\n",
              "      <th>total_bedrooms</th>\n",
              "      <th>population</th>\n",
              "      <th>households</th>\n",
              "      <th>median_income</th>\n",
              "      <th>median_house_value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>20640.000000</td>\n",
              "      <td>20640.000000</td>\n",
              "      <td>20640.000000</td>\n",
              "      <td>20640.000000</td>\n",
              "      <td>20640.000000</td>\n",
              "      <td>20640.000000</td>\n",
              "      <td>20640.000000</td>\n",
              "      <td>20640.000000</td>\n",
              "      <td>20640.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>-119.569704</td>\n",
              "      <td>35.631861</td>\n",
              "      <td>28.639486</td>\n",
              "      <td>2635.763081</td>\n",
              "      <td>537.719351</td>\n",
              "      <td>1425.476744</td>\n",
              "      <td>499.539680</td>\n",
              "      <td>3.870671</td>\n",
              "      <td>2.068558</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>2.003532</td>\n",
              "      <td>2.135952</td>\n",
              "      <td>12.585558</td>\n",
              "      <td>2181.615252</td>\n",
              "      <td>420.848774</td>\n",
              "      <td>1132.462122</td>\n",
              "      <td>382.329753</td>\n",
              "      <td>1.899822</td>\n",
              "      <td>1.153956</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>-124.350000</td>\n",
              "      <td>32.540000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.499900</td>\n",
              "      <td>0.149990</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>-121.800000</td>\n",
              "      <td>33.930000</td>\n",
              "      <td>18.000000</td>\n",
              "      <td>1447.750000</td>\n",
              "      <td>295.000000</td>\n",
              "      <td>787.000000</td>\n",
              "      <td>280.000000</td>\n",
              "      <td>2.563400</td>\n",
              "      <td>1.196000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>-118.490000</td>\n",
              "      <td>34.260000</td>\n",
              "      <td>29.000000</td>\n",
              "      <td>2127.000000</td>\n",
              "      <td>435.000000</td>\n",
              "      <td>1166.000000</td>\n",
              "      <td>409.000000</td>\n",
              "      <td>3.534800</td>\n",
              "      <td>1.797000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>-118.010000</td>\n",
              "      <td>37.710000</td>\n",
              "      <td>37.000000</td>\n",
              "      <td>3148.000000</td>\n",
              "      <td>647.000000</td>\n",
              "      <td>1725.000000</td>\n",
              "      <td>605.000000</td>\n",
              "      <td>4.743250</td>\n",
              "      <td>2.647250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>-114.310000</td>\n",
              "      <td>41.950000</td>\n",
              "      <td>52.000000</td>\n",
              "      <td>39320.000000</td>\n",
              "      <td>6445.000000</td>\n",
              "      <td>35682.000000</td>\n",
              "      <td>6082.000000</td>\n",
              "      <td>15.000100</td>\n",
              "      <td>5.000010</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          longitude      latitude  ...  median_income  median_house_value\n",
              "count  20640.000000  20640.000000  ...   20640.000000        20640.000000\n",
              "mean    -119.569704     35.631861  ...       3.870671            2.068558\n",
              "std        2.003532      2.135952  ...       1.899822            1.153956\n",
              "min     -124.350000     32.540000  ...       0.499900            0.149990\n",
              "25%     -121.800000     33.930000  ...       2.563400            1.196000\n",
              "50%     -118.490000     34.260000  ...       3.534800            1.797000\n",
              "75%     -118.010000     37.710000  ...       4.743250            2.647250\n",
              "max     -114.310000     41.950000  ...      15.000100            5.000010\n",
              "\n",
              "[8 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YYI2A_97jlD-"
      },
      "source": [
        "### Exercise 1: Standardization\n",
        "\n",
        "Previously when we worked with this dataset, we normalized the feature data in order to get it ready for the model. Normalization was the process of making all of the data fit between 0.0 and 1.0 by subtracting the minimum of each column from each data point in that column and then dividing by the delta between the maximum and minimum values.\n",
        "\n",
        "In this exercise you will need to standardize all of the feature columns. Standardization is performed by subtracting the mean value of each column from each data point in that column and then dividing by the standard deviation.\n",
        "\n",
        "> *Hint: When you are done call `describe()` and ensure that the standard deviation for every feature column is 1.0`*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kvbESp4tkTeO"
      },
      "source": [
        "#### **Student Solution**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8PMD-9e8kVDK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "outputId": "e6f9fdf7-2665-46b5-b43b-fe0c0f5f617c"
      },
      "source": [
        "# Your Code Goes Here\n",
        "housing_df.loc[:, numeric_feature_columns] = (\n",
        "    housing_df[numeric_feature_columns] - housing_df[numeric_feature_columns].min()) / (\n",
        "        housing_df[numeric_feature_columns].max() - housing_df[numeric_feature_columns].min())\n",
        "\n",
        "housing_df.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>longitude</th>\n",
              "      <th>latitude</th>\n",
              "      <th>housing_median_age</th>\n",
              "      <th>total_rooms</th>\n",
              "      <th>total_bedrooms</th>\n",
              "      <th>population</th>\n",
              "      <th>households</th>\n",
              "      <th>median_income</th>\n",
              "      <th>median_house_value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>20640.000000</td>\n",
              "      <td>20640.000000</td>\n",
              "      <td>20640.000000</td>\n",
              "      <td>20640.000000</td>\n",
              "      <td>20640.000000</td>\n",
              "      <td>20640.000000</td>\n",
              "      <td>20640.000000</td>\n",
              "      <td>20640.000000</td>\n",
              "      <td>20640.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.476125</td>\n",
              "      <td>0.328572</td>\n",
              "      <td>0.541951</td>\n",
              "      <td>0.066986</td>\n",
              "      <td>0.083290</td>\n",
              "      <td>0.039869</td>\n",
              "      <td>0.081983</td>\n",
              "      <td>0.232464</td>\n",
              "      <td>2.068558</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.199555</td>\n",
              "      <td>0.226988</td>\n",
              "      <td>0.246776</td>\n",
              "      <td>0.055486</td>\n",
              "      <td>0.065309</td>\n",
              "      <td>0.031740</td>\n",
              "      <td>0.062873</td>\n",
              "      <td>0.131020</td>\n",
              "      <td>1.153956</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.149990</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.253984</td>\n",
              "      <td>0.147715</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.036771</td>\n",
              "      <td>0.045624</td>\n",
              "      <td>0.021974</td>\n",
              "      <td>0.045881</td>\n",
              "      <td>0.142308</td>\n",
              "      <td>1.196000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.583665</td>\n",
              "      <td>0.182784</td>\n",
              "      <td>0.549020</td>\n",
              "      <td>0.054046</td>\n",
              "      <td>0.067349</td>\n",
              "      <td>0.032596</td>\n",
              "      <td>0.067094</td>\n",
              "      <td>0.209301</td>\n",
              "      <td>1.797000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.631474</td>\n",
              "      <td>0.549416</td>\n",
              "      <td>0.705882</td>\n",
              "      <td>0.080014</td>\n",
              "      <td>0.100248</td>\n",
              "      <td>0.048264</td>\n",
              "      <td>0.099326</td>\n",
              "      <td>0.292641</td>\n",
              "      <td>2.647250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>5.000010</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          longitude      latitude  ...  median_income  median_house_value\n",
              "count  20640.000000  20640.000000  ...   20640.000000        20640.000000\n",
              "mean       0.476125      0.328572  ...       0.232464            2.068558\n",
              "std        0.199555      0.226988  ...       0.131020            1.153956\n",
              "min        0.000000      0.000000  ...       0.000000            0.149990\n",
              "25%        0.253984      0.147715  ...       0.142308            1.196000\n",
              "50%        0.583665      0.182784  ...       0.209301            1.797000\n",
              "75%        0.631474      0.549416  ...       0.292641            2.647250\n",
              "max        1.000000      1.000000  ...       1.000000            5.000010\n",
              "\n",
              "[8 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1tsH6xLZkXFL"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jt-DiypL6HZ9"
      },
      "source": [
        "### One-Hot Encoding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qPpALMfd6KbK"
      },
      "source": [
        "The `ocean_proximity` column will not work with the neural network model that we are planning to build. Neural networks expect numeric values, but `ocean_proximity` contains string values.\n",
        "\n",
        "Let's remind ourselves which values it contains:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uYL4unBF6NeC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4dc87505-0083-4a6c-e7e6-4932d36a24de"
      },
      "source": [
        "sorted(housing_df['ocean_proximity'].unique())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<1H OCEAN', 'INLAND', 'ISLAND', 'NEAR BAY', 'NEAR OCEAN']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "moQf0ZjC6Rso"
      },
      "source": [
        "There are five string values. In our linear regression Colab we told TensorFlow to treat these values as a categorical column. Each string was converted to a whole number that represented their position in a vocabulary list: `0`, `1`, `2`, `3`, or `4`.\n",
        "\n",
        "For neural networks it is common to see another strategy called one-hot encoding. One-hot encoding is the process of taking a column with a fixed list of string values and turning it into multiple columns containing only zeros and ones.\n",
        "\n",
        "For instance the column `ocean_proximity` containing five strings would be converted to five columns containing ones and zeros:\n",
        "\n",
        "op_sub_hr | op_inland | op_island | op_near_bay | op_near_ocean\n",
        "----------|-----------|-----------|-------------|--------------\n",
        " 0        | 0         | 0         | 1           | 0\n",
        " 0        | 1         | 0         | 0           | 0\n",
        " 0        | 1         | 0         | 0           | 0\n",
        " 1        | 0         | 0         | 0           | 0\n",
        " 0        | 0         | 1         | 0           | 0\n",
        " 0        | 0         | 0         | 0           | 1\n",
        " 0        | 0         | 1         | 0           | 0\n",
        "\n",
        " Notice that in each row, only one column has a value of `1`. The rest are all `0`. This is the \"one-hot\" in one-hot encoding.\n",
        "\n",
        "As you can imagine, it doesn't scale well for columns with many distinct values. In our case, `5` is perfectly reasonable.\n",
        "\n",
        "Let's manually one-hot encode our data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DC2E1ItX6Q5N",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "outputId": "51edfd2d-ac1b-4e4a-811b-a1175b5620bd"
      },
      "source": [
        "for op in sorted(housing_df['ocean_proximity'].unique()):\n",
        "  op_col = op.lower().replace(' ', '_').replace('<', '')\n",
        "  housing_df[op_col] = (housing_df['ocean_proximity'] == op).astype(int)\n",
        "  feature_columns.append(op_col)\n",
        "\n",
        "feature_columns.remove('ocean_proximity')\n",
        "\n",
        "housing_df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>longitude</th>\n",
              "      <th>latitude</th>\n",
              "      <th>housing_median_age</th>\n",
              "      <th>total_rooms</th>\n",
              "      <th>total_bedrooms</th>\n",
              "      <th>population</th>\n",
              "      <th>households</th>\n",
              "      <th>median_income</th>\n",
              "      <th>median_house_value</th>\n",
              "      <th>ocean_proximity</th>\n",
              "      <th>1h_ocean</th>\n",
              "      <th>inland</th>\n",
              "      <th>island</th>\n",
              "      <th>near_bay</th>\n",
              "      <th>near_ocean</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.211155</td>\n",
              "      <td>0.567481</td>\n",
              "      <td>0.784314</td>\n",
              "      <td>0.022331</td>\n",
              "      <td>0.019863</td>\n",
              "      <td>0.008941</td>\n",
              "      <td>0.020556</td>\n",
              "      <td>0.539668</td>\n",
              "      <td>4.526</td>\n",
              "      <td>NEAR BAY</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.212151</td>\n",
              "      <td>0.565356</td>\n",
              "      <td>0.392157</td>\n",
              "      <td>0.180503</td>\n",
              "      <td>0.171477</td>\n",
              "      <td>0.067210</td>\n",
              "      <td>0.186976</td>\n",
              "      <td>0.538027</td>\n",
              "      <td>3.585</td>\n",
              "      <td>NEAR BAY</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.210159</td>\n",
              "      <td>0.564293</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.037260</td>\n",
              "      <td>0.029330</td>\n",
              "      <td>0.013818</td>\n",
              "      <td>0.028943</td>\n",
              "      <td>0.466028</td>\n",
              "      <td>3.521</td>\n",
              "      <td>NEAR BAY</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.209163</td>\n",
              "      <td>0.564293</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.032352</td>\n",
              "      <td>0.036313</td>\n",
              "      <td>0.015555</td>\n",
              "      <td>0.035849</td>\n",
              "      <td>0.354699</td>\n",
              "      <td>3.413</td>\n",
              "      <td>NEAR BAY</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.209163</td>\n",
              "      <td>0.564293</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.041330</td>\n",
              "      <td>0.043296</td>\n",
              "      <td>0.015752</td>\n",
              "      <td>0.042427</td>\n",
              "      <td>0.230776</td>\n",
              "      <td>3.422</td>\n",
              "      <td>NEAR BAY</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20635</th>\n",
              "      <td>0.324701</td>\n",
              "      <td>0.737513</td>\n",
              "      <td>0.470588</td>\n",
              "      <td>0.042296</td>\n",
              "      <td>0.057883</td>\n",
              "      <td>0.023599</td>\n",
              "      <td>0.054103</td>\n",
              "      <td>0.073130</td>\n",
              "      <td>0.781</td>\n",
              "      <td>INLAND</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20636</th>\n",
              "      <td>0.312749</td>\n",
              "      <td>0.738576</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.017676</td>\n",
              "      <td>0.023122</td>\n",
              "      <td>0.009894</td>\n",
              "      <td>0.018582</td>\n",
              "      <td>0.141853</td>\n",
              "      <td>0.771</td>\n",
              "      <td>INLAND</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20637</th>\n",
              "      <td>0.311753</td>\n",
              "      <td>0.732200</td>\n",
              "      <td>0.313725</td>\n",
              "      <td>0.057277</td>\n",
              "      <td>0.075109</td>\n",
              "      <td>0.028140</td>\n",
              "      <td>0.071041</td>\n",
              "      <td>0.082764</td>\n",
              "      <td>0.923</td>\n",
              "      <td>INLAND</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20638</th>\n",
              "      <td>0.301793</td>\n",
              "      <td>0.732200</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.047256</td>\n",
              "      <td>0.063315</td>\n",
              "      <td>0.020684</td>\n",
              "      <td>0.057227</td>\n",
              "      <td>0.094295</td>\n",
              "      <td>0.847</td>\n",
              "      <td>INLAND</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20639</th>\n",
              "      <td>0.309761</td>\n",
              "      <td>0.725824</td>\n",
              "      <td>0.294118</td>\n",
              "      <td>0.070782</td>\n",
              "      <td>0.095438</td>\n",
              "      <td>0.038790</td>\n",
              "      <td>0.086992</td>\n",
              "      <td>0.130253</td>\n",
              "      <td>0.894</td>\n",
              "      <td>INLAND</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>20640 rows × 15 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       longitude  latitude  housing_median_age  ...  island  near_bay  near_ocean\n",
              "0       0.211155  0.567481            0.784314  ...       0         1           0\n",
              "1       0.212151  0.565356            0.392157  ...       0         1           0\n",
              "2       0.210159  0.564293            1.000000  ...       0         1           0\n",
              "3       0.209163  0.564293            1.000000  ...       0         1           0\n",
              "4       0.209163  0.564293            1.000000  ...       0         1           0\n",
              "...          ...       ...                 ...  ...     ...       ...         ...\n",
              "20635   0.324701  0.737513            0.470588  ...       0         0           0\n",
              "20636   0.312749  0.738576            0.333333  ...       0         0           0\n",
              "20637   0.311753  0.732200            0.313725  ...       0         0           0\n",
              "20638   0.301793  0.732200            0.333333  ...       0         0           0\n",
              "20639   0.309761  0.725824            0.294118  ...       0         0           0\n",
              "\n",
              "[20640 rows x 15 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b6RtwkjglSwN"
      },
      "source": [
        "### Exercise 2: Split the Data\n",
        "\n",
        "We want to hold out some of the data for validation. Using standard Python or a library, split the data. Put 20% of the data in a `DataFrame` called `testing_df` and the other 80% in a `DataFrame` called `training_df`. Be sure to shuffle the data before splitting. Print the number of records in `testing_df` and `training_df` in order to check your work."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "30T4hQ4bmCM-"
      },
      "source": [
        "#### **Student Solution**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-GqS7LRJmFsf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd9bc43d-6f1a-49ff-8184-9602d30bf274"
      },
      "source": [
        "# Your Code Goes Here\n",
        "housing_df = housing_df.sample(frac=1)\n",
        "\n",
        "test_set_size = int(len(housing_df) * 0.2)\n",
        "\n",
        "testing_df = housing_df[:test_set_size]\n",
        "training_df = housing_df[test_set_size:]\n",
        "\n",
        "print(\"Size of training: {}\".format(len(training_df)))\n",
        "print(\"Size of testing : {}\".format(len(testing_df)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of training: 16512\n",
            "Size of testing : 4128\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MIOTjR4mmL_X"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hyCUUMkpn0Wi"
      },
      "source": [
        "## Building the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qv4GnnTyohQe"
      },
      "source": [
        "We will build the model using TensorFlow 2. Let's enable it and go ahead and load up TensorFlow."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6u6detBun2pN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "34f40bde-a2b9-4986-c691-6ca5bd54e9e4"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "\n",
        "import tensorflow as tf\n",
        "tf.__version__"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.4.1'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e4Pfxar2o5O2"
      },
      "source": [
        "When we built a TensorFlow `LinearRegressor` in a previous lab, we were using a pre-configured model. For our neural network regressor, we will build the model ourselves using the [Keras API of TensorFlow](https://www.tensorflow.org/guide/keras).\n",
        "\n",
        "We'll build a **sequential** model where one layer feeds into the next. Each layer will be **densely connected**, which means every node in one layer connects to every node in the next layer.\n",
        "\n",
        "A few things are required for our network. We need to have 13 input nodes since that is the number of features that we have (8 original numerical columns, plus the 5 one-hot encoded ocean proximity columns that we added). We also need to have one output node since we are trying to predict a single price value.\n",
        "\n",
        "Let's see what that would look like:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vkkNFjzop3I2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc0eb362-1085-40eb-cdeb-baafff001e61"
      },
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# Create the Sequential model.\n",
        "model = keras.Sequential()\n",
        "\n",
        "# Determine the \"input shape\", which is the number\n",
        "# of features that we will feed into the model.\n",
        "input_shape = len(feature_columns)\n",
        "\n",
        "# Create a layer that accepts our features and outputs\n",
        "# a single value, the predicted median home price.\n",
        "layer = layers.Dense(1, input_shape=[input_shape])\n",
        "\n",
        "# Add the layer to our model.\n",
        "model.add(layer)\n",
        "\n",
        "# Print out a model summary.\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_8 (Dense)              (None, 1)                 14        \n",
            "=================================================================\n",
            "Total params: 14\n",
            "Trainable params: 14\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sdu82rLhrFXM"
      },
      "source": [
        "Above we have basically recreated our linear regression from an earlier lab. We have all of our inputs directly mapping to a single output. We didn't choose an activation function, and the default activation function for a [`Dense`](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense) layer is a linear function $f(x) = x$.\n",
        "\n",
        "Note that the way we built this model was pretty verbose. You typically see simple models like this built in a more compact manner:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MTCo5CpVLV2g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed5c54e8-76b1-4d18-bf7e-93c2a34cdd1a"
      },
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "model = keras.Sequential(layers=[\n",
        "    layers.Dense(1, input_shape=[len(feature_columns)])\n",
        "])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_9 (Dense)              (None, 1)                 14        \n",
            "=================================================================\n",
            "Total params: 14\n",
            "Trainable params: 14\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pEPw3kIhMtiW"
      },
      "source": [
        "Also notice that the layers are named `dense_1`, `dense_2`, etc.\n",
        "\n",
        "If you don't supply a name for a layer, TensorFlow will provide a name for you. In small models, this isn't a problem, but you might want to have a meaningful layer name in larger models.\n",
        "\n",
        "Even in simple models, is `dense_2` a good name for the first layer in a model?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "25xCx2aCNLcc"
      },
      "source": [
        "#### Exercise 3: Name Your Layers\n",
        "\n",
        "The default naming scheme for layers can start to become confusing, especially if you repeatedly run a cell block to iterate on your model design.\n",
        "\n",
        "In this exercise consult the [`Dense` documentation](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense) and find the argument that allows you to name your layer. Use that argument in the code below to name your layer 'the_only_layer'. Note that you might have to consult the documentation for the parent classes of `Dense`.\n",
        "\n",
        "Also, don't forget to answer the question below the code block!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j3SrSWLvViFn"
      },
      "source": [
        "#### **Student Solution**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VjbI2IPsVKlo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a081fbc1-6d8c-4950-85c9-b7dfcfeffdd9"
      },
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "model = keras.Sequential(layers=[\n",
        "    layers.Dense(\n",
        "        1,\n",
        "        input_shape=[len(feature_columns)],\n",
        "        # Name your layer here\n",
        "        name='the_only_layer'\n",
        "    )\n",
        "])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "the_only_layer (Dense)       (None, 1)                 14        \n",
            "=================================================================\n",
            "Total params: 14\n",
            "Trainable params: 14\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4E3jXNquVhCn"
      },
      "source": [
        "Which class did the parameter that you used originate from?\n",
        "\n",
        "> string(?)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sdvLFUFQVsVf"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PXiiJF3fWReI"
      },
      "source": [
        "#### Making a Deep Neural Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ef2RnBnKLKjM"
      },
      "source": [
        "Where neural networks really get powerful is when you add **hidden layers**. These hidden layers can find complex patterns in your data.\n",
        "\n",
        "Let's create a model with a few hidden layers. We'll add two layers with sixty-four nodes each."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eIz2AyIPr6Qt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64807158-dfe1-4ca0-d9fe-7f663ced2a3f"
      },
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# feature_count = len(feature_columns)\n",
        "\n",
        "model = keras.Sequential([\n",
        "  layers.Dense(64, input_shape=[8]),\n",
        "  layers.Dense(64),\n",
        "  layers.Dense(1)\n",
        "])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 64)                576       \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 4,801\n",
            "Trainable params: 4,801\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4BYvMgqWtblx"
      },
      "source": [
        "We now have a deep neural network model. The model has 13 input nodes. These nodes feed into our first hidden layer of 64 nodes.\n",
        "\n",
        "The first line of our model summary tells us that we have 64 nodes and 896 parameters. The node count in 'Output Shape' makes sense, but what about the 'Param #' of 896?\n",
        "\n",
        "Remember that we have 13 input nodes feeding into 64 nodes in our first hidden layer. The layers are densely connected, so each of the 13 input nodes connects to each of the 64 nodes in the next layer. `13 * 64 = 832` connections. Add another 64 for the number of nodes in the layer, and you get the 896 number.\n",
        "\n",
        "This pattern repeats for the next layer. 64 nodes connecting to 64 nodes: `64 * 64 + 64 = 4160`.\n",
        "\n",
        "And finally 64 nodes connect to the final output node: `64 * 1 + 1 = 65`.\n",
        "\n",
        "This makes for a total of 5121 parameters in the model. Even a very small neural network like this can have a lot of trainable parameters inside of it!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ktQvZT_jS0UY"
      },
      "source": [
        "Before we start training it, we need to tell TensorFlow how and what to optimize the model for using the [`compile` method](https://keras.io/models/model/#compile). In our example below, we are optimizing for mean squared error using the [Adam optimizer](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/Adam).  We'll calculate and report the mean squared error and mean absolute error along the way."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "58EnP9hwuCxe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e38c8049-cc96-493e-ebe9-dcd0118a1db3"
      },
      "source": [
        "model.compile(\n",
        "  loss='mse',\n",
        "  optimizer='Adam',\n",
        "  metrics=['mae', 'mse'],\n",
        ")\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_10 (Dense)             (None, 64)                896       \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 5,121\n",
            "Trainable params: 5,121\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vwa9xoVwulvh"
      },
      "source": [
        "## Training the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-8Vaoryu9rv"
      },
      "source": [
        "We can now train the model using the [`fit()` method](https://keras.io/models/model/#fit). Training is performed for a specified number of **epochs**. An epoch is a full pass over the training data. In this case, we are asking to train over the full dataset 50 times.\n",
        "\n",
        "In order to get the data into the model, we don't have to write an input function like we did with the `Estimator` API. The Keras API provides for a much more direct format."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "suWnhYbUuoYC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b422d25c-a1a3-40f3-8419-2f5769920dc1"
      },
      "source": [
        "EPOCHS = 50\n",
        "\n",
        "model.fit(\n",
        "  training_df[feature_columns],\n",
        "  training_df[target_column],\n",
        "  epochs=EPOCHS,\n",
        "  validation_split=0.2,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "413/413 [==============================] - 1s 2ms/step - loss: 1.1066 - mae: 0.7636 - mse: 1.1066 - val_loss: 0.5439 - val_mae: 0.5360 - val_mse: 0.5439\n",
            "Epoch 2/50\n",
            "413/413 [==============================] - 1s 2ms/step - loss: 0.5258 - mae: 0.5333 - mse: 0.5258 - val_loss: 0.5320 - val_mae: 0.5416 - val_mse: 0.5320\n",
            "Epoch 3/50\n",
            "413/413 [==============================] - 1s 2ms/step - loss: 0.4901 - mae: 0.5101 - mse: 0.4901 - val_loss: 0.5261 - val_mae: 0.5314 - val_mse: 0.5261\n",
            "Epoch 4/50\n",
            "413/413 [==============================] - 1s 2ms/step - loss: 0.5027 - mae: 0.5224 - mse: 0.5027 - val_loss: 0.5193 - val_mae: 0.5069 - val_mse: 0.5193\n",
            "Epoch 5/50\n",
            "413/413 [==============================] - 1s 2ms/step - loss: 0.4974 - mae: 0.5145 - mse: 0.4974 - val_loss: 0.5186 - val_mae: 0.5166 - val_mse: 0.5186\n",
            "Epoch 6/50\n",
            "413/413 [==============================] - 1s 2ms/step - loss: 0.4843 - mae: 0.5061 - mse: 0.4843 - val_loss: 0.5333 - val_mae: 0.5322 - val_mse: 0.5333\n",
            "Epoch 7/50\n",
            "413/413 [==============================] - 1s 2ms/step - loss: 0.4903 - mae: 0.5134 - mse: 0.4903 - val_loss: 0.5232 - val_mae: 0.5205 - val_mse: 0.5232\n",
            "Epoch 8/50\n",
            "413/413 [==============================] - 1s 2ms/step - loss: 0.4706 - mae: 0.5026 - mse: 0.4706 - val_loss: 0.5224 - val_mae: 0.5219 - val_mse: 0.5224\n",
            "Epoch 9/50\n",
            "413/413 [==============================] - 1s 2ms/step - loss: 0.4744 - mae: 0.5045 - mse: 0.4744 - val_loss: 0.5335 - val_mae: 0.5308 - val_mse: 0.5335\n",
            "Epoch 10/50\n",
            "413/413 [==============================] - 1s 2ms/step - loss: 0.4701 - mae: 0.5020 - mse: 0.4701 - val_loss: 0.5312 - val_mae: 0.5079 - val_mse: 0.5312\n",
            "Epoch 11/50\n",
            "413/413 [==============================] - 1s 2ms/step - loss: 0.4929 - mae: 0.5148 - mse: 0.4929 - val_loss: 0.5327 - val_mae: 0.5087 - val_mse: 0.5327\n",
            "Epoch 12/50\n",
            "413/413 [==============================] - 1s 2ms/step - loss: 0.4706 - mae: 0.5063 - mse: 0.4706 - val_loss: 0.5242 - val_mae: 0.5152 - val_mse: 0.5242\n",
            "Epoch 13/50\n",
            "413/413 [==============================] - 1s 2ms/step - loss: 0.4691 - mae: 0.4976 - mse: 0.4691 - val_loss: 0.5528 - val_mae: 0.5056 - val_mse: 0.5528\n",
            "Epoch 14/50\n",
            "413/413 [==============================] - 1s 2ms/step - loss: 0.4761 - mae: 0.5008 - mse: 0.4761 - val_loss: 0.5181 - val_mae: 0.5093 - val_mse: 0.5181\n",
            "Epoch 15/50\n",
            "413/413 [==============================] - 1s 2ms/step - loss: 0.4664 - mae: 0.4997 - mse: 0.4664 - val_loss: 0.5351 - val_mae: 0.5353 - val_mse: 0.5351\n",
            "Epoch 16/50\n",
            "413/413 [==============================] - 1s 2ms/step - loss: 0.4624 - mae: 0.5003 - mse: 0.4624 - val_loss: 0.5368 - val_mae: 0.5407 - val_mse: 0.5368\n",
            "Epoch 17/50\n",
            "413/413 [==============================] - 1s 2ms/step - loss: 0.4743 - mae: 0.5035 - mse: 0.4743 - val_loss: 0.5263 - val_mae: 0.5217 - val_mse: 0.5263\n",
            "Epoch 18/50\n",
            "413/413 [==============================] - 1s 2ms/step - loss: 0.4732 - mae: 0.4973 - mse: 0.4732 - val_loss: 0.5239 - val_mae: 0.5155 - val_mse: 0.5239\n",
            "Epoch 19/50\n",
            "413/413 [==============================] - 1s 2ms/step - loss: 0.4703 - mae: 0.4999 - mse: 0.4703 - val_loss: 0.5284 - val_mae: 0.5204 - val_mse: 0.5284\n",
            "Epoch 20/50\n",
            "413/413 [==============================] - 1s 2ms/step - loss: 0.4815 - mae: 0.5036 - mse: 0.4815 - val_loss: 0.5255 - val_mae: 0.5044 - val_mse: 0.5255\n",
            "Epoch 21/50\n",
            "413/413 [==============================] - 1s 2ms/step - loss: 0.4731 - mae: 0.5039 - mse: 0.4731 - val_loss: 0.5215 - val_mae: 0.5163 - val_mse: 0.5215\n",
            "Epoch 22/50\n",
            "413/413 [==============================] - 1s 2ms/step - loss: 0.4686 - mae: 0.5013 - mse: 0.4686 - val_loss: 0.5265 - val_mae: 0.5094 - val_mse: 0.5265\n",
            "Epoch 23/50\n",
            "413/413 [==============================] - 1s 2ms/step - loss: 0.4664 - mae: 0.5008 - mse: 0.4664 - val_loss: 0.5270 - val_mae: 0.5097 - val_mse: 0.5270\n",
            "Epoch 24/50\n",
            "413/413 [==============================] - 1s 2ms/step - loss: 0.4814 - mae: 0.5052 - mse: 0.4814 - val_loss: 0.5288 - val_mae: 0.5042 - val_mse: 0.5288\n",
            "Epoch 25/50\n",
            "413/413 [==============================] - 1s 2ms/step - loss: 0.4625 - mae: 0.4957 - mse: 0.4625 - val_loss: 0.5311 - val_mae: 0.5165 - val_mse: 0.5311\n",
            "Epoch 26/50\n",
            "413/413 [==============================] - 1s 2ms/step - loss: 0.4753 - mae: 0.5093 - mse: 0.4753 - val_loss: 0.5280 - val_mae: 0.5119 - val_mse: 0.5280\n",
            "Epoch 27/50\n",
            "413/413 [==============================] - 1s 2ms/step - loss: 0.4848 - mae: 0.5093 - mse: 0.4848 - val_loss: 0.5223 - val_mae: 0.5132 - val_mse: 0.5223\n",
            "Epoch 28/50\n",
            "413/413 [==============================] - 1s 2ms/step - loss: 0.4643 - mae: 0.4968 - mse: 0.4643 - val_loss: 0.5322 - val_mae: 0.5024 - val_mse: 0.5322\n",
            "Epoch 29/50\n",
            "413/413 [==============================] - 1s 2ms/step - loss: 0.4673 - mae: 0.4984 - mse: 0.4673 - val_loss: 0.5335 - val_mae: 0.5067 - val_mse: 0.5335\n",
            "Epoch 30/50\n",
            "413/413 [==============================] - 1s 2ms/step - loss: 0.4733 - mae: 0.5043 - mse: 0.4733 - val_loss: 0.5255 - val_mae: 0.5209 - val_mse: 0.5255\n",
            "Epoch 31/50\n",
            "413/413 [==============================] - 1s 2ms/step - loss: 0.4649 - mae: 0.4973 - mse: 0.4649 - val_loss: 0.5267 - val_mae: 0.5079 - val_mse: 0.5267\n",
            "Epoch 32/50\n",
            "413/413 [==============================] - 1s 2ms/step - loss: 0.4621 - mae: 0.4967 - mse: 0.4621 - val_loss: 0.5269 - val_mae: 0.5092 - val_mse: 0.5269\n",
            "Epoch 33/50\n",
            "413/413 [==============================] - 1s 2ms/step - loss: 0.4654 - mae: 0.4980 - mse: 0.4654 - val_loss: 0.5784 - val_mae: 0.5125 - val_mse: 0.5784\n",
            "Epoch 34/50\n",
            "413/413 [==============================] - 1s 2ms/step - loss: 0.4692 - mae: 0.5008 - mse: 0.4692 - val_loss: 0.5227 - val_mae: 0.5039 - val_mse: 0.5227\n",
            "Epoch 35/50\n",
            "413/413 [==============================] - 1s 2ms/step - loss: 0.4746 - mae: 0.4996 - mse: 0.4746 - val_loss: 0.5231 - val_mae: 0.5118 - val_mse: 0.5231\n",
            "Epoch 36/50\n",
            "413/413 [==============================] - 1s 2ms/step - loss: 0.4608 - mae: 0.4970 - mse: 0.4608 - val_loss: 0.5276 - val_mae: 0.5025 - val_mse: 0.5276\n",
            "Epoch 37/50\n",
            "413/413 [==============================] - 1s 2ms/step - loss: 0.4785 - mae: 0.5031 - mse: 0.4785 - val_loss: 0.5325 - val_mae: 0.5304 - val_mse: 0.5325\n",
            "Epoch 38/50\n",
            "413/413 [==============================] - 1s 2ms/step - loss: 0.4972 - mae: 0.5134 - mse: 0.4972 - val_loss: 0.5251 - val_mae: 0.5064 - val_mse: 0.5251\n",
            "Epoch 39/50\n",
            "413/413 [==============================] - 1s 2ms/step - loss: 0.4740 - mae: 0.5006 - mse: 0.4740 - val_loss: 0.5361 - val_mae: 0.5045 - val_mse: 0.5361\n",
            "Epoch 40/50\n",
            "413/413 [==============================] - 1s 2ms/step - loss: 0.4436 - mae: 0.4860 - mse: 0.4436 - val_loss: 0.5351 - val_mae: 0.5301 - val_mse: 0.5351\n",
            "Epoch 41/50\n",
            "413/413 [==============================] - 1s 2ms/step - loss: 0.4771 - mae: 0.5044 - mse: 0.4771 - val_loss: 0.5476 - val_mae: 0.5018 - val_mse: 0.5476\n",
            "Epoch 42/50\n",
            "413/413 [==============================] - 1s 2ms/step - loss: 0.4651 - mae: 0.4961 - mse: 0.4651 - val_loss: 0.5261 - val_mae: 0.5217 - val_mse: 0.5261\n",
            "Epoch 43/50\n",
            "413/413 [==============================] - 1s 2ms/step - loss: 0.4846 - mae: 0.5082 - mse: 0.4846 - val_loss: 0.5331 - val_mae: 0.5264 - val_mse: 0.5331\n",
            "Epoch 44/50\n",
            "413/413 [==============================] - 1s 2ms/step - loss: 0.4655 - mae: 0.5023 - mse: 0.4655 - val_loss: 0.5267 - val_mae: 0.5049 - val_mse: 0.5267\n",
            "Epoch 45/50\n",
            "413/413 [==============================] - 1s 2ms/step - loss: 0.4583 - mae: 0.4922 - mse: 0.4583 - val_loss: 0.5254 - val_mae: 0.5120 - val_mse: 0.5254\n",
            "Epoch 46/50\n",
            "413/413 [==============================] - 1s 2ms/step - loss: 0.4661 - mae: 0.4982 - mse: 0.4661 - val_loss: 0.5345 - val_mae: 0.5025 - val_mse: 0.5345\n",
            "Epoch 47/50\n",
            "413/413 [==============================] - 1s 2ms/step - loss: 0.4545 - mae: 0.4933 - mse: 0.4545 - val_loss: 0.5252 - val_mae: 0.5100 - val_mse: 0.5252\n",
            "Epoch 48/50\n",
            "413/413 [==============================] - 1s 2ms/step - loss: 0.4635 - mae: 0.4981 - mse: 0.4635 - val_loss: 0.5304 - val_mae: 0.5051 - val_mse: 0.5304\n",
            "Epoch 49/50\n",
            "413/413 [==============================] - 1s 2ms/step - loss: 0.4789 - mae: 0.5048 - mse: 0.4789 - val_loss: 0.5281 - val_mae: 0.5121 - val_mse: 0.5281\n",
            "Epoch 50/50\n",
            "413/413 [==============================] - 1s 2ms/step - loss: 0.4754 - mae: 0.5046 - mse: 0.4754 - val_loss: 0.5230 - val_mae: 0.5113 - val_mse: 0.5230\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fc9d4ad46d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TuTsElUdv4uU"
      },
      "source": [
        "## Validating the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pFLnpozdwYbL"
      },
      "source": [
        "We can now see how well our model performs on our validation test set. In order to get the model to make predictions, we use the [`predict` method](https://keras.io/models/model/#predict)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qzC4Q6kuxy-m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c627e1a-3ad0-4784-bfbd-44076f4731bd"
      },
      "source": [
        "predictions = model.predict(testing_df[feature_columns])\n",
        "\n",
        "predictions"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2.6235507],\n",
              "       [2.3353362],\n",
              "       [1.017668 ],\n",
              "       ...,\n",
              "       [2.9445941],\n",
              "       [1.2377841],\n",
              "       [2.3761418]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3nAGc2VQyIGu"
      },
      "source": [
        "Notice that the predictions are lists of lists. This is because neural networks can return more than one prediction per input. We set this network up to have a single final node, but could have had more."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XH_6-meyzBIj"
      },
      "source": [
        "### Exercise 4: Calculating RMSE\n",
        "\n",
        "At this point we have the predicted values from our test features and the actual values. In this exercise you are tasked with computing the root-mean squared error of those predictions. Given the predictions stored in `predictions` above, write code that computes the root mean squared error of those predictions vs. the truth found in `testing_df`. Print the root mean squared error."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GuY3HZAZl4z7"
      },
      "source": [
        "#### **Student Solution**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_flON0FHc_yW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "393d33e5-71a3-45c0-9792-854045a14c53"
      },
      "source": [
        "# Your Code Goes here\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "rmse = mean_squared_error(testing_df['median_house_value'], predictions, squared=False)\n",
        "rmse"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6832837039045299"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4DncNYnRdBQ6"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "33SMPRXPeLmv"
      },
      "source": [
        "## Improving the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YAtfBRAXeSYW"
      },
      "source": [
        "In the exercise above, you likely got a root mean squared error very close to the error we got in the linear regression lab. What's going on? I thought deep learning models were supposed to be really, really good!\n",
        "\n",
        "Deep learning models can be really good, but they often require a bit of hyperparameter tuning. Aside from the breadth and depth of the hidden layers, the activation function for the model can have a big impact on how a model performs.\n",
        "\n",
        "Earlier we mentioned that the default activation function for `Dense` layers is the linear function $f(x) = x$. It turns out that if you stack layers of linear functions, you just get a single linear function, so the network that we built is basically just one big linear regression.\n",
        "\n",
        "We can change the activation function layer by layer for our model. In order to do that, we just pass an `activation` argument to our `Dense` class. Keras has [many built-in activations](https://www.tensorflow.org/api_docs/python/tf/keras/activations) that you can reference by name like:\n",
        "\n",
        "```python\n",
        "  layers.Dense(64, activation='sigmoid')\n",
        "```\n",
        "\n",
        "For activations that aren't built into Keras, you can use the full path to their class:\n",
        "\n",
        "```python\n",
        "  layers.Dense(64, activation=tf.nn.swish)\n",
        "```\n",
        "\n",
        "The [`tf.nn` namespace](https://www.tensorflow.org/api_docs/python/tf/nn) is a little crowded, but there are activations functions in there including [`swish`](https://www.tensorflow.org/api_docs/python/tf/nn/swish), [`leaky_relu`](https://www.tensorflow.org/api_docs/python/tf/nn/leaky_relu), and more."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M-BNO2fAeOZ2"
      },
      "source": [
        "### Exercise 5: A Better Activation Function\n",
        "\n",
        "Experiment with different activation functions and find one that performs better than the linear activation that we used above. You can set the activation function on any or all of the layers in the network. The functions don't have to be the same.\n",
        "\n",
        "Print out the root mean squared error once you find an acceptable activation function."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cMgsYuE0ld9g"
      },
      "source": [
        "#### **Student Solution**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "id": "QVQqBagb7ZSt",
        "outputId": "e3cafbfe-d8b3-4e62-9a55-689d40bc3b4d"
      },
      "source": [
        "training_df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>longitude</th>\n",
              "      <th>latitude</th>\n",
              "      <th>housing_median_age</th>\n",
              "      <th>total_rooms</th>\n",
              "      <th>total_bedrooms</th>\n",
              "      <th>population</th>\n",
              "      <th>households</th>\n",
              "      <th>median_income</th>\n",
              "      <th>median_house_value</th>\n",
              "      <th>ocean_proximity</th>\n",
              "      <th>1h_ocean</th>\n",
              "      <th>inland</th>\n",
              "      <th>island</th>\n",
              "      <th>near_bay</th>\n",
              "      <th>near_ocean</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>12868</th>\n",
              "      <td>0.298805</td>\n",
              "      <td>0.656748</td>\n",
              "      <td>0.019608</td>\n",
              "      <td>0.556870</td>\n",
              "      <td>0.545003</td>\n",
              "      <td>0.242412</td>\n",
              "      <td>0.472291</td>\n",
              "      <td>0.278844</td>\n",
              "      <td>1.513</td>\n",
              "      <td>INLAND</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19567</th>\n",
              "      <td>0.336653</td>\n",
              "      <td>0.538789</td>\n",
              "      <td>0.294118</td>\n",
              "      <td>0.033674</td>\n",
              "      <td>0.058038</td>\n",
              "      <td>0.024692</td>\n",
              "      <td>0.061503</td>\n",
              "      <td>0.094557</td>\n",
              "      <td>1.039</td>\n",
              "      <td>INLAND</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12789</th>\n",
              "      <td>0.289841</td>\n",
              "      <td>0.646121</td>\n",
              "      <td>0.705882</td>\n",
              "      <td>0.076479</td>\n",
              "      <td>0.113594</td>\n",
              "      <td>0.042322</td>\n",
              "      <td>0.096530</td>\n",
              "      <td>0.064744</td>\n",
              "      <td>0.610</td>\n",
              "      <td>INLAND</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3515</th>\n",
              "      <td>0.585657</td>\n",
              "      <td>0.181722</td>\n",
              "      <td>0.647059</td>\n",
              "      <td>0.044000</td>\n",
              "      <td>0.061763</td>\n",
              "      <td>0.031307</td>\n",
              "      <td>0.065779</td>\n",
              "      <td>0.251672</td>\n",
              "      <td>1.957</td>\n",
              "      <td>&lt;1H OCEAN</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20484</th>\n",
              "      <td>0.560757</td>\n",
              "      <td>0.184910</td>\n",
              "      <td>0.313725</td>\n",
              "      <td>0.077547</td>\n",
              "      <td>0.096436</td>\n",
              "      <td>0.047703</td>\n",
              "      <td>0.081237</td>\n",
              "      <td>0.361216</td>\n",
              "      <td>2.186</td>\n",
              "      <td>&lt;1H OCEAN</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7645</th>\n",
              "      <td>0.605578</td>\n",
              "      <td>0.134963</td>\n",
              "      <td>0.176471</td>\n",
              "      <td>0.047790</td>\n",
              "      <td>0.088454</td>\n",
              "      <td>0.049497</td>\n",
              "      <td>0.090775</td>\n",
              "      <td>0.236459</td>\n",
              "      <td>1.140</td>\n",
              "      <td>&lt;1H OCEAN</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12013</th>\n",
              "      <td>0.675299</td>\n",
              "      <td>0.145590</td>\n",
              "      <td>0.411765</td>\n",
              "      <td>0.066585</td>\n",
              "      <td>0.061297</td>\n",
              "      <td>0.037025</td>\n",
              "      <td>0.059365</td>\n",
              "      <td>0.336106</td>\n",
              "      <td>2.146</td>\n",
              "      <td>INLAND</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11859</th>\n",
              "      <td>0.339641</td>\n",
              "      <td>0.807651</td>\n",
              "      <td>0.588235</td>\n",
              "      <td>0.079480</td>\n",
              "      <td>0.102886</td>\n",
              "      <td>0.037613</td>\n",
              "      <td>0.095215</td>\n",
              "      <td>0.074309</td>\n",
              "      <td>0.580</td>\n",
              "      <td>INLAND</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10235</th>\n",
              "      <td>0.640438</td>\n",
              "      <td>0.140276</td>\n",
              "      <td>0.490196</td>\n",
              "      <td>0.018897</td>\n",
              "      <td>0.024829</td>\n",
              "      <td>0.006839</td>\n",
              "      <td>0.024667</td>\n",
              "      <td>0.216383</td>\n",
              "      <td>1.339</td>\n",
              "      <td>&lt;1H OCEAN</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14164</th>\n",
              "      <td>0.726096</td>\n",
              "      <td>0.024442</td>\n",
              "      <td>0.647059</td>\n",
              "      <td>0.043949</td>\n",
              "      <td>0.057728</td>\n",
              "      <td>0.020376</td>\n",
              "      <td>0.057392</td>\n",
              "      <td>0.105412</td>\n",
              "      <td>1.618</td>\n",
              "      <td>NEAR OCEAN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>16512 rows × 15 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       longitude  latitude  housing_median_age  ...  island  near_bay  near_ocean\n",
              "12868   0.298805  0.656748            0.019608  ...       0         0           0\n",
              "19567   0.336653  0.538789            0.294118  ...       0         0           0\n",
              "12789   0.289841  0.646121            0.705882  ...       0         0           0\n",
              "3515    0.585657  0.181722            0.647059  ...       0         0           0\n",
              "20484   0.560757  0.184910            0.313725  ...       0         0           0\n",
              "...          ...       ...                 ...  ...     ...       ...         ...\n",
              "7645    0.605578  0.134963            0.176471  ...       0         0           0\n",
              "12013   0.675299  0.145590            0.411765  ...       0         0           0\n",
              "11859   0.339641  0.807651            0.588235  ...       0         0           0\n",
              "10235   0.640438  0.140276            0.490196  ...       0         0           0\n",
              "14164   0.726096  0.024442            0.647059  ...       0         0           1\n",
              "\n",
              "[16512 rows x 15 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HuWQBoAslfo0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57bda223-dc17-46af-f6cf-879b222de6fd"
      },
      "source": [
        "# Your Code Goes Here\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "feature_count = len(feature_columns)\n",
        "\n",
        "model = keras.Sequential([\n",
        "    layers.Dense(64, activation=tf.nn.relu, input_shape=[feature_count]),\n",
        "    layers.Dense(64, activation=tf.nn.relu),\n",
        "    layers.Dense(1, activation=tf.keras.activations.swish)\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    loss='mse',\n",
        "    optimizer='Adam',\n",
        "    metrics=['mae', 'mse'],\n",
        ")\n",
        "\n",
        "EPOCHS = 50\n",
        "\n",
        "model.fit(\n",
        "    training_df[feature_columns],\n",
        "    training_df[target_column],\n",
        "    epochs=EPOCHS,\n",
        "    validation_split=0.2,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "413/413 [==============================] - 1s 2ms/step - loss: 1.7693 - mae: 0.9611 - mse: 1.7693 - val_loss: 0.5363 - val_mae: 0.5402 - val_mse: 0.5363\n",
            "Epoch 2/50\n",
            "413/413 [==============================] - 1s 2ms/step - loss: 0.4986 - mae: 0.5128 - mse: 0.4986 - val_loss: 0.5156 - val_mae: 0.4872 - val_mse: 0.5156\n",
            "Epoch 3/50\n",
            "413/413 [==============================] - 1s 2ms/step - loss: 0.4723 - mae: 0.4937 - mse: 0.4723 - val_loss: 0.4841 - val_mae: 0.4879 - val_mse: 0.4841\n",
            "Epoch 4/50\n",
            "413/413 [==============================] - 1s 2ms/step - loss: 0.4586 - mae: 0.4854 - mse: 0.4586 - val_loss: 0.4767 - val_mae: 0.4744 - val_mse: 0.4767\n",
            "Epoch 5/50\n",
            "413/413 [==============================] - 1s 2ms/step - loss: 0.4481 - mae: 0.4738 - mse: 0.4481 - val_loss: 0.4683 - val_mae: 0.4939 - val_mse: 0.4683\n",
            "Epoch 6/50\n",
            "413/413 [==============================] - 1s 2ms/step - loss: 0.4251 - mae: 0.4628 - mse: 0.4251 - val_loss: 0.4575 - val_mae: 0.4584 - val_mse: 0.4575\n",
            "Epoch 7/50\n",
            "413/413 [==============================] - 1s 2ms/step - loss: 0.4112 - mae: 0.4569 - mse: 0.4112 - val_loss: 0.4312 - val_mae: 0.4605 - val_mse: 0.4312\n",
            "Epoch 8/50\n",
            "413/413 [==============================] - 1s 2ms/step - loss: 0.3976 - mae: 0.4445 - mse: 0.3976 - val_loss: 0.4231 - val_mae: 0.4578 - val_mse: 0.4231\n",
            "Epoch 9/50\n",
            "413/413 [==============================] - 1s 2ms/step - loss: 0.3969 - mae: 0.4428 - mse: 0.3969 - val_loss: 0.4181 - val_mae: 0.4440 - val_mse: 0.4181\n",
            "Epoch 10/50\n",
            "413/413 [==============================] - 1s 2ms/step - loss: 0.3798 - mae: 0.4321 - mse: 0.3798 - val_loss: 0.4081 - val_mae: 0.4556 - val_mse: 0.4081\n",
            "Epoch 11/50\n",
            "413/413 [==============================] - 1s 2ms/step - loss: 0.3696 - mae: 0.4263 - mse: 0.3696 - val_loss: 0.4160 - val_mae: 0.4573 - val_mse: 0.4160\n",
            "Epoch 12/50\n",
            "413/413 [==============================] - 1s 2ms/step - loss: 0.3797 - mae: 0.4297 - mse: 0.3797 - val_loss: 0.3990 - val_mae: 0.4285 - val_mse: 0.3990\n",
            "Epoch 13/50\n",
            "413/413 [==============================] - 1s 2ms/step - loss: 0.3724 - mae: 0.4278 - mse: 0.3724 - val_loss: 0.3998 - val_mae: 0.4303 - val_mse: 0.3998\n",
            "Epoch 14/50\n",
            "413/413 [==============================] - 1s 2ms/step - loss: 0.3457 - mae: 0.4089 - mse: 0.3457 - val_loss: 0.3970 - val_mae: 0.4473 - val_mse: 0.3970\n",
            "Epoch 15/50\n",
            "413/413 [==============================] - 1s 2ms/step - loss: 0.3596 - mae: 0.4129 - mse: 0.3596 - val_loss: 0.3813 - val_mae: 0.4192 - val_mse: 0.3813\n",
            "Epoch 16/50\n",
            "413/413 [==============================] - 1s 2ms/step - loss: 0.3619 - mae: 0.4172 - mse: 0.3619 - val_loss: 0.3781 - val_mae: 0.4241 - val_mse: 0.3781\n",
            "Epoch 17/50\n",
            "413/413 [==============================] - 1s 2ms/step - loss: 0.3363 - mae: 0.4061 - mse: 0.3363 - val_loss: 0.3773 - val_mae: 0.4219 - val_mse: 0.3773\n",
            "Epoch 18/50\n",
            "413/413 [==============================] - 1s 2ms/step - loss: 0.3424 - mae: 0.4080 - mse: 0.3424 - val_loss: 0.3862 - val_mae: 0.4181 - val_mse: 0.3862\n",
            "Epoch 19/50\n",
            "413/413 [==============================] - 1s 2ms/step - loss: 0.3320 - mae: 0.4036 - mse: 0.3320 - val_loss: 0.3779 - val_mae: 0.4335 - val_mse: 0.3779\n",
            "Epoch 20/50\n",
            "413/413 [==============================] - 1s 2ms/step - loss: 0.3336 - mae: 0.3995 - mse: 0.3336 - val_loss: 0.3765 - val_mae: 0.4126 - val_mse: 0.3765\n",
            "Epoch 21/50\n",
            "413/413 [==============================] - 1s 2ms/step - loss: 0.3343 - mae: 0.3978 - mse: 0.3343 - val_loss: 0.3652 - val_mae: 0.4109 - val_mse: 0.3652\n",
            "Epoch 22/50\n",
            "413/413 [==============================] - 1s 2ms/step - loss: 0.3314 - mae: 0.3977 - mse: 0.3314 - val_loss: 0.4371 - val_mae: 0.4346 - val_mse: 0.4371\n",
            "Epoch 23/50\n",
            "413/413 [==============================] - 1s 2ms/step - loss: 0.3328 - mae: 0.3981 - mse: 0.3328 - val_loss: 0.3749 - val_mae: 0.4117 - val_mse: 0.3749\n",
            "Epoch 24/50\n",
            "413/413 [==============================] - 1s 2ms/step - loss: 0.3319 - mae: 0.3962 - mse: 0.3319 - val_loss: 0.3628 - val_mae: 0.4082 - val_mse: 0.3628\n",
            "Epoch 25/50\n",
            "413/413 [==============================] - 1s 2ms/step - loss: 0.3191 - mae: 0.3882 - mse: 0.3191 - val_loss: 0.3682 - val_mae: 0.4214 - val_mse: 0.3682\n",
            "Epoch 26/50\n",
            "413/413 [==============================] - 1s 2ms/step - loss: 0.3291 - mae: 0.3953 - mse: 0.3291 - val_loss: 0.3519 - val_mae: 0.4125 - val_mse: 0.3519\n",
            "Epoch 27/50\n",
            "413/413 [==============================] - 1s 2ms/step - loss: 0.3245 - mae: 0.3912 - mse: 0.3245 - val_loss: 0.3778 - val_mae: 0.4035 - val_mse: 0.3778\n",
            "Epoch 28/50\n",
            "413/413 [==============================] - 1s 2ms/step - loss: 0.3256 - mae: 0.3943 - mse: 0.3256 - val_loss: 0.3579 - val_mae: 0.4072 - val_mse: 0.3579\n",
            "Epoch 29/50\n",
            "413/413 [==============================] - 1s 2ms/step - loss: 0.3104 - mae: 0.3845 - mse: 0.3104 - val_loss: 0.3707 - val_mae: 0.4013 - val_mse: 0.3707\n",
            "Epoch 30/50\n",
            "413/413 [==============================] - 1s 2ms/step - loss: 0.3078 - mae: 0.3837 - mse: 0.3078 - val_loss: 0.3649 - val_mae: 0.4320 - val_mse: 0.3649\n",
            "Epoch 31/50\n",
            "413/413 [==============================] - 1s 2ms/step - loss: 0.3176 - mae: 0.3929 - mse: 0.3176 - val_loss: 0.3551 - val_mae: 0.4211 - val_mse: 0.3551\n",
            "Epoch 32/50\n",
            "413/413 [==============================] - 1s 2ms/step - loss: 0.3101 - mae: 0.3846 - mse: 0.3101 - val_loss: 0.3659 - val_mae: 0.4392 - val_mse: 0.3659\n",
            "Epoch 33/50\n",
            "413/413 [==============================] - 1s 2ms/step - loss: 0.3097 - mae: 0.3831 - mse: 0.3097 - val_loss: 0.3463 - val_mae: 0.4001 - val_mse: 0.3463\n",
            "Epoch 34/50\n",
            "413/413 [==============================] - 1s 2ms/step - loss: 0.3141 - mae: 0.3854 - mse: 0.3141 - val_loss: 0.3545 - val_mae: 0.4112 - val_mse: 0.3545\n",
            "Epoch 35/50\n",
            "413/413 [==============================] - 1s 2ms/step - loss: 0.3176 - mae: 0.3872 - mse: 0.3176 - val_loss: 0.3396 - val_mae: 0.3999 - val_mse: 0.3396\n",
            "Epoch 36/50\n",
            "413/413 [==============================] - 1s 2ms/step - loss: 0.3075 - mae: 0.3813 - mse: 0.3075 - val_loss: 0.3558 - val_mae: 0.3950 - val_mse: 0.3558\n",
            "Epoch 37/50\n",
            "413/413 [==============================] - 1s 2ms/step - loss: 0.2981 - mae: 0.3786 - mse: 0.2981 - val_loss: 0.3405 - val_mae: 0.4023 - val_mse: 0.3405\n",
            "Epoch 38/50\n",
            "413/413 [==============================] - 1s 2ms/step - loss: 0.3058 - mae: 0.3793 - mse: 0.3058 - val_loss: 0.3417 - val_mae: 0.3922 - val_mse: 0.3417\n",
            "Epoch 39/50\n",
            "413/413 [==============================] - 1s 2ms/step - loss: 0.3009 - mae: 0.3781 - mse: 0.3009 - val_loss: 0.3403 - val_mae: 0.4001 - val_mse: 0.3403\n",
            "Epoch 40/50\n",
            "413/413 [==============================] - 1s 2ms/step - loss: 0.3067 - mae: 0.3813 - mse: 0.3067 - val_loss: 0.3328 - val_mae: 0.3889 - val_mse: 0.3328\n",
            "Epoch 41/50\n",
            "413/413 [==============================] - 1s 2ms/step - loss: 0.3017 - mae: 0.3774 - mse: 0.3017 - val_loss: 0.3591 - val_mae: 0.4330 - val_mse: 0.3591\n",
            "Epoch 42/50\n",
            "413/413 [==============================] - 1s 2ms/step - loss: 0.3036 - mae: 0.3786 - mse: 0.3036 - val_loss: 0.3401 - val_mae: 0.3855 - val_mse: 0.3401\n",
            "Epoch 43/50\n",
            "413/413 [==============================] - 1s 2ms/step - loss: 0.3053 - mae: 0.3796 - mse: 0.3053 - val_loss: 0.3406 - val_mae: 0.3895 - val_mse: 0.3406\n",
            "Epoch 44/50\n",
            "413/413 [==============================] - 1s 2ms/step - loss: 0.3083 - mae: 0.3746 - mse: 0.3083 - val_loss: 0.3403 - val_mae: 0.3847 - val_mse: 0.3403\n",
            "Epoch 45/50\n",
            "413/413 [==============================] - 1s 2ms/step - loss: 0.2922 - mae: 0.3691 - mse: 0.2922 - val_loss: 0.3360 - val_mae: 0.3893 - val_mse: 0.3360\n",
            "Epoch 46/50\n",
            "413/413 [==============================] - 1s 2ms/step - loss: 0.2955 - mae: 0.3727 - mse: 0.2955 - val_loss: 0.3377 - val_mae: 0.3956 - val_mse: 0.3377\n",
            "Epoch 47/50\n",
            "413/413 [==============================] - 1s 2ms/step - loss: 0.2995 - mae: 0.3724 - mse: 0.2995 - val_loss: 0.3306 - val_mae: 0.3875 - val_mse: 0.3306\n",
            "Epoch 48/50\n",
            "413/413 [==============================] - 1s 2ms/step - loss: 0.2994 - mae: 0.3739 - mse: 0.2994 - val_loss: 0.3415 - val_mae: 0.4008 - val_mse: 0.3415\n",
            "Epoch 49/50\n",
            "413/413 [==============================] - 1s 2ms/step - loss: 0.2939 - mae: 0.3710 - mse: 0.2939 - val_loss: 0.3260 - val_mae: 0.3778 - val_mse: 0.3260\n",
            "Epoch 50/50\n",
            "413/413 [==============================] - 1s 2ms/step - loss: 0.2842 - mae: 0.3646 - mse: 0.2842 - val_loss: 0.3275 - val_mae: 0.3812 - val_mse: 0.3275\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fc9c39dc1d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pVJPiVzh8U7c",
        "outputId": "ff4413f7-37ec-4eca-beb3-da39f1308b82"
      },
      "source": [
        "predictions = model.predict(testing_df[feature_columns])\n",
        "predictions"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[3.778885 ],\n",
              "       [1.8306324],\n",
              "       [0.6583254],\n",
              "       ...,\n",
              "       [2.6525545],\n",
              "       [1.0388312],\n",
              "       [2.6696036]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w4RKIUCK34Cw",
        "outputId": "3cb117fa-7240-479d-b8c8-cfaf9045520e"
      },
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "rmse = mean_squared_error(testing_df['median_house_value'], predictions, squared=False)\n",
        "rmse"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5481113993557271"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J2csiDfLlgtT"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7E63WyKpmleN"
      },
      "source": [
        "## Visualizing Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ixm_bQDGuYbr"
      },
      "source": [
        "At this point, we have a pretty solid neural network regression model. It performs better than our linear regression model, though it does take a while to train.\n",
        "\n",
        "Training time is largely a product of two factors:\n",
        "\n",
        "1. The size of the model\n",
        "1. The number of epochs\n",
        "\n",
        "Larger models take longer to train. That shouldn't come as a surprise. Remember from above that we calculated the number of parameters in our model. Every layer that is densely connected adds many more parameters that need to be adjusted during training.\n",
        "\n",
        "Our goal is to find a model that is big enough, but not too big. This, it turns out, is very much an area where experimentation is required.\n",
        "\n",
        "The second determination of model training time is the number of epochs. We can choose an arbitrary number of epochs from one to infinity. How many do we need?\n",
        "\n",
        "It turns out that we can be much more scientific about this parameter. As a model begins to converge, there is less and less benefit for each subsequent epoch.\n",
        "\n",
        "More training does not necessarily mean a better model.\n",
        "\n",
        "There are a few ways to determine the appropriate number of epochs. One is to plot the error and see when it flattens out.\n",
        "\n",
        "It turns out that our model actually returns the error values when you fit the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KbhsGp9_0LOK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e12fbe19-fe1d-4954-f162-8a527f644204"
      },
      "source": [
        "model = keras.Sequential([\n",
        "  layers.Dense(64, input_shape=[feature_count]),\n",
        "  layers.Dense(64),\n",
        "  layers.Dense(1)\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "  loss='mse',\n",
        "  optimizer='Adam',\n",
        "  metrics=['mae', 'mse'],\n",
        ")\n",
        "\n",
        "EPOCHS = 5\n",
        "\n",
        "history = model.fit(\n",
        "  training_df[feature_columns],\n",
        "  training_df[target_column],\n",
        "  epochs=EPOCHS,\n",
        "  verbose=0,                     # New parameter to make model training silent\n",
        "  validation_split=0.2,\n",
        ")\n",
        "\n",
        "history.history"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'loss': [0.6810020804405212,\n",
              "  0.516365647315979,\n",
              "  0.5027371644973755,\n",
              "  0.4919399321079254,\n",
              "  0.4845682978630066],\n",
              " 'mae': [0.6021654009819031,\n",
              "  0.5248839855194092,\n",
              "  0.5173166990280151,\n",
              "  0.5129233002662659,\n",
              "  0.5091933608055115],\n",
              " 'mse': [0.6810020804405212,\n",
              "  0.516365647315979,\n",
              "  0.5027371644973755,\n",
              "  0.4919399321079254,\n",
              "  0.4845682978630066],\n",
              " 'val_loss': [0.5535661578178406,\n",
              "  0.5296065211296082,\n",
              "  0.5383336544036865,\n",
              "  0.5160989761352539,\n",
              "  0.5364993214607239],\n",
              " 'val_mae': [0.5475435256958008,\n",
              "  0.5114800333976746,\n",
              "  0.5463980436325073,\n",
              "  0.5072331428527832,\n",
              "  0.5056113004684448],\n",
              " 'val_mse': [0.5535661578178406,\n",
              "  0.5296065211296082,\n",
              "  0.5383336544036865,\n",
              "  0.5160989761352539,\n",
              "  0.5364993214607239]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VqUttCc121Mo"
      },
      "source": [
        "Notice that the `history.history` contains our model's loss (`loss`), mean absolute error (`mae`), mean squared error (`mse`), validation loss (`val_loss`), validation mean absolute error (`val_mae`), and validation mean squared error (`val_mse`) at each epoch.\n",
        "\n",
        "It would be useful to plot the error over time. In the next exercise, you will create a visualization that will help us determine when to stop training the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8_Pn1ZFe3mEp"
      },
      "source": [
        "### Exercise 6: Plotting Error"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HERuu5h332oV"
      },
      "source": [
        "Use `matplotlib.pyplot` or `seaborn` to create a line plot that shows the mean squared error and the validation mean squared error per epoch.\n",
        "\n",
        "In the code block below, we save the errors per epoch in the variable `history`. Inspect the variable and plot a line plot which has the epoch on the x-axis and the mean squared error on the y-axis. There should be two lines on the visualization: mean absolute error and validation mean absolute error.\n",
        "\n",
        "Note that we created the model with the default activation function. Use the activation function that you found to be more useful in exercise 5.\n",
        "\n",
        "The result should be a line plot of epoch and error with two lines similar to:\n",
        "\n",
        "![alt text](https://i.imgur.com/0YDzVhq.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qK0v5ehj58nx"
      },
      "source": [
        "model = keras.Sequential([\n",
        "  layers.Dense(64, input_shape=[feature_count]),\n",
        "  layers.Dense(64),\n",
        "  layers.Dense(1)\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "  loss='mse',\n",
        "  optimizer='Adam',\n",
        "  metrics=['mae', 'mse'],\n",
        ")\n",
        "\n",
        "EPOCHS = 100\n",
        "\n",
        "history = model.fit(\n",
        "  training_df[feature_columns],\n",
        "  training_df[target_column],\n",
        "  epochs=EPOCHS,\n",
        "  verbose=0,\n",
        "  validation_split=0.2,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H743wjkE56AV"
      },
      "source": [
        "#### **Student Solution**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4rN-BXBX6KkV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 509
        },
        "outputId": "54c544b2-5199-45e1-b22c-0b959dae9a9e"
      },
      "source": [
        "# Your Code Goes Here\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "X = np.arange(EPOCHS)\n",
        "plt.figure(figsize=(20,10))\n",
        "plt.plot(X, history.history['mse'])\n",
        "plt.plot(X, history.history['val_mse'])\n",
        "plt.legend(['Mean Squared Error', 'Validation Mean Squared Error'])\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"MSE\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q6XBdKqj6L7Z"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xqp93VIH7eEJ"
      },
      "source": [
        "### Interpreting Loss Visualizations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_B4Cwtbs7ifl"
      },
      "source": [
        "We have now created a visualization that should look something like this:\n",
        "\n",
        "![alt text](https://i.imgur.com/0YDzVhq.png)\n",
        "\n",
        "But how do we interpret this visualization?\n",
        "\n",
        "The blue line is the mean squared error for the training data. You can see it plummeting fast as the model quickly learns.\n",
        "\n",
        "The orange line is the validation data. This is a holdout set of data that the model checks after each epoch. You can see it dropping pretty quickly, too, but then it seems to stabilize somewhat by 20 epochs.\n",
        "\n",
        "Toward the right side of the graph, you can see that our validation set says volatile but relatively flat, while our training data set keeps getting better and better.\n",
        "\n",
        "Should we train more or less?\n",
        "\n",
        "The constantly reducing blue line is actually a signal of overfitting on the training data.\n",
        "\n",
        "The flat(ish) orange line signals this model is as good as we can get.\n",
        "\n",
        "For this model we could possibly stop training after even 25 epochs and get similar performance.\n",
        "\n",
        "But how do you know when to stop?\n",
        "\n",
        "Luckily there is an *early stopping* algorithm that allows a model to stop training when validation data isn't improving.\n",
        "\n",
        "In the example below, we set up a model to train for 1000 epochs; however, we add an early stopping callback. Early stopping stops training when the model isn't progressing upon validation.\n",
        "\n",
        "If you run the code block below, you'll see far fewer than 1000 epochs run."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lgCZjgOT7JqO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "312abae1-2091-471f-bb89-815a867c39b5"
      },
      "source": [
        "model = keras.Sequential([\n",
        "  layers.Dense(64, input_shape=[feature_count]),\n",
        "  layers.Dense(64),\n",
        "  layers.Dense(1)\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "  loss='mse',\n",
        "  optimizer='Adam',\n",
        "  metrics=['mae', 'mse'],\n",
        ")\n",
        "\n",
        "EPOCHS = 1000\n",
        "\n",
        "early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
        "\n",
        "history = model.fit(\n",
        "  training_df[feature_columns],\n",
        "  training_df[target_column],\n",
        "  epochs=EPOCHS,\n",
        "  validation_split=0.2,\n",
        "  callbacks=[early_stop],\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "413/413 [==============================] - 1s 2ms/step - loss: 0.9611 - mae: 0.7096 - mse: 0.9611 - val_loss: 0.5705 - val_mae: 0.5767 - val_mse: 0.5705\n",
            "Epoch 2/1000\n",
            "413/413 [==============================] - 1s 2ms/step - loss: 0.5338 - mae: 0.5375 - mse: 0.5338 - val_loss: 0.5348 - val_mae: 0.5113 - val_mse: 0.5348\n",
            "Epoch 3/1000\n",
            "413/413 [==============================] - 1s 2ms/step - loss: 0.5107 - mae: 0.5204 - mse: 0.5107 - val_loss: 0.5228 - val_mae: 0.5180 - val_mse: 0.5228\n",
            "Epoch 4/1000\n",
            "413/413 [==============================] - 1s 2ms/step - loss: 0.4857 - mae: 0.5064 - mse: 0.4857 - val_loss: 0.5266 - val_mae: 0.5434 - val_mse: 0.5266\n",
            "Epoch 5/1000\n",
            "413/413 [==============================] - 1s 2ms/step - loss: 0.5013 - mae: 0.5185 - mse: 0.5013 - val_loss: 0.5216 - val_mae: 0.5301 - val_mse: 0.5216\n",
            "Epoch 6/1000\n",
            "413/413 [==============================] - 1s 2ms/step - loss: 0.4727 - mae: 0.5052 - mse: 0.4727 - val_loss: 0.5272 - val_mae: 0.5015 - val_mse: 0.5272\n",
            "Epoch 7/1000\n",
            "413/413 [==============================] - 1s 2ms/step - loss: 0.4675 - mae: 0.5028 - mse: 0.4675 - val_loss: 0.5379 - val_mae: 0.5420 - val_mse: 0.5379\n",
            "Epoch 8/1000\n",
            "413/413 [==============================] - 1s 2ms/step - loss: 0.4828 - mae: 0.5111 - mse: 0.4828 - val_loss: 0.5364 - val_mae: 0.5081 - val_mse: 0.5364\n",
            "Epoch 9/1000\n",
            "413/413 [==============================] - 1s 2ms/step - loss: 0.4810 - mae: 0.5064 - mse: 0.4810 - val_loss: 0.5757 - val_mae: 0.5786 - val_mse: 0.5757\n",
            "Epoch 10/1000\n",
            "413/413 [==============================] - 1s 2ms/step - loss: 0.4706 - mae: 0.5051 - mse: 0.4706 - val_loss: 0.5463 - val_mae: 0.5071 - val_mse: 0.5463\n",
            "Epoch 11/1000\n",
            "413/413 [==============================] - 1s 2ms/step - loss: 0.4763 - mae: 0.5015 - mse: 0.4763 - val_loss: 0.5302 - val_mae: 0.5064 - val_mse: 0.5302\n",
            "Epoch 12/1000\n",
            "413/413 [==============================] - 1s 2ms/step - loss: 0.4669 - mae: 0.4977 - mse: 0.4669 - val_loss: 0.5277 - val_mae: 0.5083 - val_mse: 0.5277\n",
            "Epoch 13/1000\n",
            "413/413 [==============================] - 1s 2ms/step - loss: 0.4653 - mae: 0.4997 - mse: 0.4653 - val_loss: 0.5409 - val_mae: 0.5079 - val_mse: 0.5409\n",
            "Epoch 14/1000\n",
            "413/413 [==============================] - 1s 2ms/step - loss: 0.4764 - mae: 0.5086 - mse: 0.4764 - val_loss: 0.5261 - val_mae: 0.5075 - val_mse: 0.5261\n",
            "Epoch 15/1000\n",
            "413/413 [==============================] - 1s 2ms/step - loss: 0.4663 - mae: 0.4978 - mse: 0.4663 - val_loss: 0.5543 - val_mae: 0.5063 - val_mse: 0.5543\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ehTtTmPT61oH"
      },
      "source": [
        "## Conclusion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "21IdNfUG64H6"
      },
      "source": [
        "We have now learned how to build a deep neural network to solve a regression problem. We have visualized our loss in order to determine when we might stop training, and we have utilized early stopping to avoid wasting time training a model.\n",
        "\n",
        "Welcome to deep neural networks. They are deceptively simple to build, but they are very complex to master. When you can build a model to fit a domain, you can create amazing predictions that rival human experts."
      ]
    }
  ]
}